{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "from autodiff.activation import ReLU, Linear\n",
    "from autodiff.network import Network, NetworkParams\n",
    "\n",
    "file_path = 'test-parameters.pkl'\n",
    "\n",
    "with open(file_path, 'rb') as file:\n",
    "    data = pkl.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_def: NetworkParams = {\n",
    "    \"input_shape\": 2,\n",
    "    \"output_shape\": 1,\n",
    "    \"layers\": [\n",
    "        {\n",
    "            \"input_shape\": 2,\n",
    "            \"n_neurons\": len(data['w1']),\n",
    "            \"weight_init\": data['w1'],\n",
    "            \"bias_init\": data['b1'] ,\n",
    "            \"activation\": ReLU(),\n",
    "        },\n",
    "        {\n",
    "            \"input_shape\": len(data['w1']),\n",
    "            \"n_neurons\": len(data['w2']),\n",
    "            \"weight_init\": data['w2'],\n",
    "            \"bias_init\": data['b2'] ,\n",
    "            \"activation\": ReLU(),\n",
    "        },\n",
    "        {\n",
    "            \"input_shape\": len(data['w2']),\n",
    "            \"n_neurons\": len(data['w3']),\n",
    "            \"weight_init\": data['w3'],\n",
    "            \"bias_init\": data['b3'] ,\n",
    "            \"activation\": Linear(), \n",
    "        }\n",
    "    ]\n",
    "} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.5.0-cp312-none-macosx_11_0_arm64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (3.2.1)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (69.5.1)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jinja2->torch) (2.1.5)\n",
      "Downloading torch-2.5.0-cp312-none-macosx_11_0_arm64.whl (64.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Installing collected packages: sympy, jinja2, torch\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.12\n",
      "    Uninstalling sympy-1.12:\n",
      "      Successfully uninstalled sympy-1.12\n",
      "Successfully installed jinja2-3.1.4 sympy-1.13.1 torch-2.5.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Backprop Grads\n",
      "####################\n",
      "First Layer w_grads:    [[-0.18804252 -0.28206378]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.53346761  0.80020142]\n",
      " [ 0.14224417  0.21336625]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [-0.02312626 -0.0346894 ]\n",
      " [ 0.          0.        ]]\n",
      "First Layer b_grads:    [-0.09402126  0.          0.          0.26673381  0.07112208  0.\n",
      "  0.          0.         -0.01156313  0.        ]\n",
      "####################\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from model import SimpleNet, set_model_weights\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input_data = [2,3]\n",
    "target_data = [1]\n",
    "\n",
    "def get_loss(y, y_hat): \n",
    "    return 0.5*((y_hat - y)**2)\n",
    "\n",
    "# custom network\n",
    "network = Network(network_def)\n",
    "y_pred = network.forward(input_data)\n",
    "y = target_data\n",
    "loss = get_loss(y, y_pred)\n",
    "network.backward(y_pred - y) \n",
    "print(\"Custom Backprop Grads\")\n",
    "print(\"#\"*20)\n",
    "print(\"First Layer w_grads:   \", network.layers[0].w_grads)\n",
    "print(\"First Layer b_grads:   \", network.layers[0].b_grads)\n",
    "print(\"#\"*20)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "input_data = torch.tensor([2,3], dtype=torch.float64)\n",
    "target_data = torch.tensor([1], dtype=torch.float64)\n",
    "\n",
    "# pytorch network\n",
    "model = SimpleNet()\n",
    "set_model_weights(data,model)\n",
    "output = model(input_data)\n",
    "loss = criterion(output, target_data)/2\n",
    "\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1_weight_grad: tensor([[-0.1880, -0.2821],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.5335,  0.8002],\n",
      "        [ 0.1422,  0.2134],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [-0.0231, -0.0347],\n",
      "        [ 0.0000,  0.0000]], dtype=torch.float64)\n",
      "fc1_bias_grad: tensor([-0.0940,  0.0000,  0.0000,  0.2667,  0.0711,  0.0000,  0.0000,  0.0000,\n",
      "        -0.0116,  0.0000], dtype=torch.float64)\n",
      "<class 'tuple'>\n",
      "(tensor([[-0.1880, -0.2821],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.5335,  0.8002],\n",
      "        [ 0.1422,  0.2134],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [-0.0231, -0.0347],\n",
      "        [ 0.0000,  0.0000]], dtype=torch.float64), tensor([-0.0940,  0.0000,  0.0000,  0.2667,  0.0711,  0.0000,  0.0000,  0.0000,\n",
      "        -0.0116,  0.0000], dtype=torch.float64))\n"
     ]
    }
   ],
   "source": [
    "# Check what get_gradients() returns\n",
    "gradients = model.get_gradients()\n",
    "print(type(gradients))  # Check the type\n",
    "print(gradients)         # Print to see the structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1_weight_grad: tensor([[-0.1880, -0.2821],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.5335,  0.8002],\n",
      "        [ 0.1422,  0.2134],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [-0.0231, -0.0347],\n",
      "        [ 0.0000,  0.0000]], dtype=torch.float64)\n",
      "fc1_bias_grad: tensor([-0.0940,  0.0000,  0.0000,  0.2667,  0.0711,  0.0000,  0.0000,  0.0000,\n",
      "        -0.0116,  0.0000], dtype=torch.float64)\n",
      "[[-0.18804252 -0.28206378]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.53346761  0.80020142]\n",
      " [ 0.14224417  0.21336625]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [-0.02312626 -0.0346894 ]\n",
      " [ 0.          0.        ]]\n",
      "Gradients match: True\n"
     ]
    }
   ],
   "source": [
    "# Extract the weight gradients (first element of the tuple)\n",
    "pytorch_w_gradients = model.get_gradients()[0].detach().cpu().numpy()\n",
    "\n",
    "# Custom backpropagation gradients (already given)\n",
    "custom_w_gradients = np.array([\n",
    "    [-0.18804252, -0.28206378],\n",
    "    [0, 0],\n",
    "    [0, 0],\n",
    "    [0.53346761, 0.80020142],\n",
    "    [0.14224417, 0.21336625],\n",
    "    [0, 0],\n",
    "    [0, 0],\n",
    "    [0, 0],\n",
    "    [-0.02312626, -0.0346894],\n",
    "    [0, 0]\n",
    "])\n",
    "\n",
    "# Comparison function\n",
    "def compare_gradients(pytorch_gradients: np.ndarray, custom_backprop_gradients: np.ndarray, tolerance: float) -> bool:\n",
    "    if pytorch_gradients.shape != custom_backprop_gradients.shape:\n",
    "        raise ValueError('The shapes do not match')\n",
    "\n",
    "    return np.allclose(pytorch_gradients, custom_backprop_gradients, atol=tolerance)\n",
    "\n",
    "# Run the comparison\n",
    "result = compare_gradients(\n",
    "    pytorch_gradients=pytorch_w_gradients,\n",
    "    custom_backprop_gradients=custom_w_gradients,\n",
    "    tolerance=0.001\n",
    ")\n",
    "\n",
    "print(f\"Gradients match: {result}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
