{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "import numpy as np\n",
    "from autodiff.activation import ReLU, Sigmoid, Linear\n",
    "from autodiff.network import Network, NetworkParams, PredictionType\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.array([[1]])\n",
    "input = np.array([1])\n",
    "\n",
    "w.shape\n",
    "input.shape\n",
    "\n",
    "w @ input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Network Test\n",
    "\n",
    "Comparing with hand-calculated simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_def: NetworkParams = {\n",
    "    \"input_shape\": 1,\n",
    "    \"output_shape\": 1,\n",
    "    \"prediction_type\": PredictionType.REGRESSION,\n",
    "    \"layers\": [\n",
    "        {\n",
    "            \"input_shape\": 1,\n",
    "            \"n_neurons\": 1,\n",
    "            \"weights_init\": [[1]],\n",
    "            \"bias_init\": [0],\n",
    "            \"activation\": Linear(),\n",
    "        },\n",
    "        {\n",
    "            \"input_shape\": 1,\n",
    "            \"n_neurons\": 2,\n",
    "            \"weights_init\": [[0.8],[-0.6]],\n",
    "            \"bias_init\": [-0.5,-0.5],\n",
    "            \"activation\": ReLU(),\n",
    "        },\n",
    "        {\n",
    "            \"input_shape\": 2,\n",
    "            \"n_neurons\": 1,\n",
    "            \"weights_init\": [[0.5, 0.5]],\n",
    "            \"bias_init\": [0],\n",
    "            \"activation\": Linear(),\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "network = Network(network_def)\n",
    "# network.print_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.]\n",
      "[0.         0.10000002]\n",
      "[0.05000001]\n",
      "[0.10124999]\n"
     ]
    }
   ],
   "source": [
    "y_hat = network.forward([-1])\n",
    "# print(y_hat)\n",
    "y = 0.5\n",
    "\n",
    "def get_loss(y, y_hat): \n",
    "    return 0.5*(y_hat - y)**2\n",
    "\n",
    "loss = get_loss(y, y_hat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.44999999]\n",
      "[-0.22499999 -0.22499999]\n",
      "[0.135]\n",
      "[0.135]\n"
     ]
    }
   ],
   "source": [
    "delta = y_hat - y\n",
    "\n",
    "network.backward(delta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape: 1\n",
      "output_shape: 1\n",
      "Num layers: 3\n",
      "\n",
      "Layer [0]\n",
      "Neurons:    1; Inputs: 1\n",
      "Weights:(1, 1) [[1.]]\n",
      "Biases:(1,)  [0.]\n",
      "W grads: (1, 1) [[0.04499999]]\n",
      "B grads: (1,)   [-0.04499999]\n",
      "Activation: [-1.]\n",
      "Last input: [-1]\n",
      "\n",
      "Layer [1]\n",
      "Neurons:    2; Inputs: 1\n",
      "Weights:(2, 1) [[ 0.8]\n",
      " [-0.6]]\n",
      "Biases:(2,)  [-0.5 -0.5]\n",
      "W grads: (2, 1) [[0.225]\n",
      " [0.225]]\n",
      "B grads: (2,)   [-0.225 -0.225]\n",
      "Activation: [0.         0.10000002]\n",
      "Last input: [-1.]\n",
      "\n",
      "Layer [2]\n",
      "Neurons:    1; Inputs: 2\n",
      "Weights:(1, 2) [[0.5 0.5]]\n",
      "Biases:(1,)  [0.]\n",
      "W grads: (1, 2) [[ 0.         -0.04500001]]\n",
      "B grads: (1,)   [-0.45]\n",
      "Activation: [0.05000001]\n",
      "Last input: [0.         0.10000002]\n"
     ]
    }
   ],
   "source": [
    "network.print_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another Example\n",
    "\n",
    "Foreward and Backward example [here](https://towardsdatascience.com/neural-networks-forward-pass-and-backpropagation-be3b75a1cfcc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape: 1\n",
      "output_shape: 1\n",
      "Num layers: 3\n",
      "\n",
      "Layer [0]\n",
      "Neurons:    2; Inputs: 1\n",
      "Weights:(2, 1) [[-0.00748682]\n",
      " [ 0.5364436 ]]\n",
      "Biases:(2,)  [-0.82304513 -0.735939  ]\n",
      "W grads: (2, 1) [[0.]\n",
      " [0.]]\n",
      "B grads: (2,)   [0. 0.]\n",
      "Activation: [0. 0.]\n",
      "Last input: [0.]\n",
      "\n",
      "Layer [1]\n",
      "Neurons:    2; Inputs: 2\n",
      "Weights:(2, 2) [[-0.27234524  0.1896159 ]\n",
      " [-0.01401001  0.56065756]]\n",
      "Biases:(2,)  [-0.06275153  0.18710935]\n",
      "W grads: (2, 2) [[0. 0.]\n",
      " [0. 0.]]\n",
      "B grads: (2,)   [0. 0.]\n",
      "Activation: [0. 0.]\n",
      "Last input: [0. 0.]\n",
      "\n",
      "Layer [2]\n",
      "Neurons:    1; Inputs: 2\n",
      "Weights:(1, 2) [[-0.2136969  -0.13899273]]\n",
      "Biases:(1,)  [-0.6755334]\n",
      "W grads: (1, 2) [[0. 0.]]\n",
      "B grads: (1,)   [0.]\n",
      "Activation: [0.]\n",
      "Last input: [0. 0.]\n"
     ]
    }
   ],
   "source": [
    "w1 = -0.00748682\n",
    "w2 = 0.5364436\n",
    "w3 = -0.27234524\n",
    "w4 = -0.01401001\n",
    "w5 = 0.1896159\n",
    "w6 = 0.56065756\n",
    "w7 = -0.2136969\n",
    "w8 = -0.13899273\n",
    "b1 = -0.82304513\n",
    "b2 = -0.735939\n",
    "b3 = -0.06275153\n",
    "b4 = 0.18710935\n",
    "b5 = -0.6755334\n",
    "\n",
    "network_def: NetworkParams = {\n",
    "    \"input_shape\": 1,\n",
    "    \"output_shape\": 1,\n",
    "    \"prediction_type\": PredictionType.REGRESSION,\n",
    "    \"layers\": [\n",
    "        {\n",
    "            \"input_shape\": 1,\n",
    "            \"n_neurons\": 2,\n",
    "            \"weights_init\": [[w1], [w2]],\n",
    "            \"bias_init\": [b1,b2],\n",
    "            \"activation\": ReLU(),\n",
    "        },\n",
    "        {\n",
    "            \"input_shape\": 2,\n",
    "            \"n_neurons\": 2,\n",
    "            \"weights_init\": [[w3,w5],[w4 ,w6]],\n",
    "            \"bias_init\": [b3,b4],\n",
    "            \"activation\": ReLU(),\n",
    "        },\n",
    "        {\n",
    "            \"input_shape\": 2,\n",
    "            \"n_neurons\": 1,\n",
    "            \"weights_init\": [[w7, w8]],\n",
    "            \"bias_init\": [b5],\n",
    "            \"activation\": Linear(),\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "network = Network(network_def)\n",
    "network.print_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0.]\n",
      "[0.         0.18710935]\n",
      "[-0.70154025]\n",
      "\n",
      "Backwards pass:\n",
      "[-3.40308051]\n",
      "N=1; M=2\n",
      "[0.72722774 0.47300344]\n",
      "N=2; M=2\n",
      "[-0.00662678  0.26519295]\n",
      "N=2; M=1\n",
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "network.zero_grad()\n",
    "x = [1]\n",
    "y = 1\n",
    "y_hat = network.forward(x)\n",
    "\n",
    "print()\n",
    "print(\"Backwards pass:\")\n",
    "network.backward(2*(y_hat-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape: 1\n",
      "output_shape: 1\n",
      "Num layers: 3\n",
      "\n",
      "Layer [2]\n",
      "Neurons:    1; Inputs: 2\n",
      "Weights:(1, 2) [[-0.2136969  -0.13899273]]\n",
      "Biases:(1,)  [-0.6755334]\n",
      "W grads: (1, 2) [[ 0.        -0.6367482]]\n",
      "B grads: (1,)   [-3.4030805]\n",
      "Activation: [-0.70154025]\n",
      "Last input: [0.         0.18710935]\n",
      "\n",
      "Layer [1]\n",
      "Neurons:    2; Inputs: 2\n",
      "Weights:(2, 2) [[-0.27234524  0.1896159 ]\n",
      " [-0.01401001  0.56065756]]\n",
      "Biases:(2,)  [-0.06275153  0.18710935]\n",
      "W grads: (2, 2) [[0. 0.]\n",
      " [0. 0.]]\n",
      "B grads: (2,)   [0.         0.47300345]\n",
      "Activation: [0.         0.18710935]\n",
      "Last input: [0. 0.]\n",
      "\n",
      "Layer [0]\n",
      "Neurons:    2; Inputs: 1\n",
      "Weights:(2, 1) [[-0.00748682]\n",
      " [ 0.5364436 ]]\n",
      "Biases:(2,)  [-0.82304513 -0.735939  ]\n",
      "W grads: (2, 1) [[0.]\n",
      " [0.]]\n",
      "B grads: (2,)   [0. 0.]\n",
      "Activation: [0. 0.]\n",
      "Last input: [1]\n"
     ]
    }
   ],
   "source": [
    "network.print_params(reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another Example\n",
    "\n",
    "Foreward and Backward example [here](https://theneuralblog.com/forward-pass-backpropagation-example/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_def: NetworkParams = {\n",
    "    \"input_shape\": 2,\n",
    "    \"output_shape\": 2,\n",
    "    \"prediction_type\": PredictionType.REGRESSION,\n",
    "    \"layers\": [\n",
    "        {\n",
    "            \"input_shape\": 2,\n",
    "            \"n_neurons\": 2,\n",
    "            \"weights_init\": [[0.1, 0.3],[0.2, 0.4]],\n",
    "            \"bias_init\": [0.25, 0.25],\n",
    "            \"activation\": Sigmoid(),\n",
    "        },\n",
    "        {\n",
    "            \"input_shape\": 2,\n",
    "            \"n_neurons\": 2,\n",
    "            \"weights_init\": [[0.5, 0.6],[0.7, 0.8]],\n",
    "            \"bias_init\": [0.35, 0.35],\n",
    "            \"activation\": Sigmoid(),\n",
    "        },\n",
    "    ]\n",
    "}\n",
    "\n",
    "network = Network(network_def)\n",
    "# network.print_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.60108788 0.61538376]\n",
      "[0.74674229 0.76905089]\n",
      "y_hat=array([0.74674229, 0.76905089])\n",
      "\n",
      "Backwards pass:\n",
      "[ 1.39348458 -0.36189822]\n",
      "[0.09320028 0.13305148]\n",
      "[0.00853307 0.0193009 ]\n"
     ]
    }
   ],
   "source": [
    "network.zero_grad()\n",
    "x = [0.1, 0.5]\n",
    "y = [0.05, 0.95]\n",
    "y_hat = network.forward(x)\n",
    "print(f\"{y_hat=}\")\n",
    "\n",
    "print()\n",
    "print(\"Backwards pass:\")\n",
    "network.backward(2*(y_hat-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "syde577",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
